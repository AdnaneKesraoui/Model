{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import step, pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import urllib.request\n",
    "import csv\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "\n",
    "@step\n",
    "def read_tweets_from_file(file_path: str) -> list:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        tweets = file.readlines()\n",
    "    return [tweet.strip() for tweet in tweets]\n",
    "\n",
    "@step\n",
    "def read_labels_from_file(labels_path: str) -> list:\n",
    "    with open(labels_path, 'r', encoding='utf-8') as file:\n",
    "        labels = [int(line.strip()) for line in file]\n",
    "    return labels\n",
    "\n",
    "@step\n",
    "def preprocess_step(texts: list) -> list:\n",
    "    preprocessed_texts = []\n",
    "    for text in texts:\n",
    "        new_text = []\n",
    "        for t in text.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            new_text.append(t)\n",
    "        preprocessed_texts.append(\" \".join(new_text))\n",
    "    return preprocessed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "import uuid\n",
    "\n",
    "@step\n",
    "def insert_preprocessed_tweets_into_cassandra(processed_texts: list):\n",
    "  \n",
    "\n",
    "    CASSANDRA_CLUSTER = ['localhost']\n",
    "    KEYSPACE = 'mykeyspace'\n",
    "    TABLE_NAME = 'preprocessed_tweets'\n",
    "\n",
    "    cluster = Cluster(CASSANDRA_CLUSTER)\n",
    "    session = cluster.connect(KEYSPACE)\n",
    "\n",
    "    def insert_preprocessed_tweet(tweet_text):\n",
    "        query = f\"INSERT INTO {TABLE_NAME} (id, tweet_text) VALUES (%s, %s)\"\n",
    "        session.execute(query, (uuid.uuid4(), tweet_text))\n",
    "\n",
    "    for tweet_text in processed_texts:\n",
    "        stored_output=insert_preprocessed_tweet(tweet_text)\n",
    "    \n",
    "    print(\"All preprocessed tweets have been inserted into Cassandra.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, padding='max_length', max_length=self.max_length, truncation=True, return_attention_mask=True)\n",
    "        return {\n",
    "            'input_ids': torch.tensor(encoding['input_ids']),\n",
    "            'attention_mask': torch.tensor(encoding['attention_mask']),\n",
    "            'labels': torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "@step\n",
    "def train_model_step(texts: list, labels: list) -> str:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    task = 'sentiment'\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=len(label_mapping)).to(device)\n",
    "\n",
    "    dataset = TweetsDataset(texts, labels, tokenizer)\n",
    "    train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = \"trained_sentiment_model\"\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def model_inference_step(texts: list) -> list:\n",
    "    predictions = []\n",
    "\n",
    "    # Set the model path to the trained model directory\n",
    "    model_path = 'trained_sentiment_model'\n",
    "    \n",
    "    # Load tokenizer and model from your trained model directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    # Assuming you have label mappings like before in the `train_model_step`\n",
    "    # If they are stored differently for the new model, adjust as necessary.\n",
    "    label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    labels = list(label_mapping.keys())\n",
    "\n",
    "    for text in texts:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        ranking = np.argsort(scores)[::-1]\n",
    "        text_predictions = [labels[i] for i in ranking] \n",
    "        predictions.append(text_predictions[0])\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluate_predictions(predictions: list, true_labels: list) -> dict:\n",
    "    predictions_mapped = [label_mapping[pred] for pred in predictions]\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions_mapped)\n",
    "    precision = precision_score(true_labels, predictions_mapped, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions_mapped, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions_mapped, average='weighted', zero_division=0)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@step\n",
    "def visualize_metrics(metrics: dict) -> str:\n",
    "    \n",
    "    names = list(metrics.keys())\n",
    "    values = list(metrics.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(names, values)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Evaluation Metrics')\n",
    "    \n",
    "    figure_path = 'metrics_figure.png'\n",
    "    plt.savefig(figure_path)\n",
    "    plt.close()\n",
    "    \n",
    "    return figure_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36msentiment_analysis_pipeline_with_evaluation\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 33)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mread_labels_from_file\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mread_labels_from_file\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mread_tweets_from_file\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mread_tweets_from_file\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mpreprocess_step\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_step\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36minsert_preprocessed_tweets_into_cassandra\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36minsert_preprocessed_tweets_into_cassandra\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_inference_step\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_inference_step\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1m9s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_predictions\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_predictions\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.263s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mvisualize_metrics\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mvisualize_metrics\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.624s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m1m11s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@pipeline\n",
    "def sentiment_analysis_pipeline_with_evaluation(file_path: str, labels_path: str):\n",
    "    tweets = read_tweets_from_file(file_path)\n",
    "    true_labels = read_labels_from_file(labels_path)\n",
    "    processed_texts = preprocess_step(tweets)\n",
    "    insert_preprocessed_tweets_into_cassandra(processed_texts)\n",
    "    #train_model_step(processed_texts, true_labels)\n",
    "    predictions = model_inference_step(processed_texts)\n",
    "    evaluation_results = evaluate_predictions(predictions, true_labels)\n",
    "    visualize_metrics(evaluation_results)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../val_text.txt' \n",
    "    labels_path = '../val_labels.txt' \n",
    "    sentiment_analysis_pipeline_with_evaluation(file_path, labels_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CASSANDRA_CLUSTER = ['localhost']\n",
    "# KEYSPACE = 'mykeyspace'\n",
    "# TABLE_NAME = 'preprocessed_tweets'    \n",
    "\n",
    "\n",
    "# def fetch_and_print_preprocessed_tweets():\n",
    "#     query = f\"SELECT id, tweet_text FROM {TABLE_NAME}\"\n",
    "#     rows = session.execute(query)\n",
    "    \n",
    "#     for row in rows:\n",
    "#         print(f\"ID: {row.id}, Tweet: {row.tweet_text}\")\n",
    "# fetch_and_print_preprocessed_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_read_tweets_from_file\u001b[39m():\n\u001b[0;32m      4\u001b[0m     tweets \u001b[38;5;241m=\u001b[39m read_tweets_from_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../val_text.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytest'"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "def test_read_tweets_from_file():\n",
    "    tweets = read_tweets_from_file('../val_text.txt')\n",
    "    assert isinstance(tweets, list)\n",
    "    assert all(isinstance(tweet, str) for tweet in tweets)\n",
    "\n",
    "def test_preprocess_step():\n",
    "    test_tweets = [\n",
    "        \"@user1 this is a test! http://testurl.com\",\n",
    "        \"Normal text without users or urls\"\n",
    "    ]\n",
    "    expected_output = [\n",
    "        \"@user this is a test! http\",\n",
    "        \"Normal text without users or urls\"\n",
    "    ]\n",
    "    preprocessed = preprocess_step(test_tweets)\n",
    "    assert preprocessed == expected_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
